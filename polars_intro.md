## An introduction to Polars
Polars is an extremely promising library for processing tabular data not only for the performance benefits it offers but because of the expressiveness and safety of its API. Being a newer library than Pandas it may not offer the same features and be as fully integrated into other common libraries in the data scientist’s stack. However, it has come a long way in a short time, is already being integrated into key libraries, and allows users to go to and from other formats quite easily.

Polars is designed for working with tabular data on a single machine. It positions itself as a competitor to Pandas, and to some extent, Dask. From a performance standpoint, it is multi-threaded as opposed to single threaded like Pandas. Its lazy evaluation and query optimizer allows it to minimize compute and memory use. In terms of design, its API is more composable and stricter than Pandas’, which makes it easier to program performant code that has fewer bugs, especially schema-related bugs. The benefits of composability, lazy evaluation, query optimization, and schema strictness are features of Spark’s DataFrames API. Given that Polars can take advantage of parallel processing on a single machine, the use cases for Spark are confined to working with data that must be distributed across multiple machines.

A lot of the hype around Polars is about how fast it is - their own tagline is “a blazingly fast DataFrame library for manipulating structured data.” It accomplishes this in a few ways. It is written in Rust without external dependencies. Its streaming API allows you to process data without storing it all in memory. It parallelizes work across the cores of your machine. Finally, it uses a combination of Apache Arrow[^what_is_arrow] and a query engine to process queries in a vectorized way, optimize CPU usage, and reduce the amount of data you have to process.

[^what_is_arrow]: Apache Arrow is a data storage format specification that has implementations in a bunch of different languages, including Rust and Python. It is a specification for in-memory storage, so isn’t meant to replace disk storage formats like Parquet. The advantage of Arrow, besides the SIMD CPU optimizations, is that it allows for data to be used by programs written in different programming languages without a bunch of ser/deser.

The fact that it is written in Rust is important because of how this allows for parallelization and vectorization, but it is important to note that you can do these things in other languages (e.g., C and C++). When using Pandas, you may call vectorized (and potentially multi-threaded) functions from C and Fortran libraries because of how Pandas is built on numpy.[^conda_note] However, pandas adds bloat on top of numpy arrays and a lot of the other code was written in pure Python and refactoring such a huge legacy codebase is a challenge for the Pandas community. For our purposes, I think Stan Siebert’s take is balanced and productive. “My take on the Rust stuff is I view it in the same light as when we used C and Fortran historically, it’s just Rust is a nicer language in many ways. And so being a nicer language means you certainly could have written any of these things in C a long time ago and they would have been much faster, it’s just that you didn’t want to write that C code…”[^rust_note]

[^conda_note]: Getting the most out of these C and Fortran dependencies is why conda exists.

[^rust_note]: He continues to say, “I would happily see Rust completely replace C as the dominant extension language in Python.” This is one of the reasons I’m most interested in Polars. Stan is the Senior Director of Community Innovation at Anaconda managing their open source developers (e.g. working on Numba and Jupyter).

The other feature of Polars performance I would like to focus on is its query engine. It is first necessary to understand the difference between eager and lazy evaluation however. Eager evaluation is when a command is executed immediately after it is encountered by a program. Lazy evaluation means that code will only be executed when it is explicitly needed by the program. Lazy evaluation allows you to build long chains of instructions without executing them. This capability allows you to assess entire sets of operations and optimize them and is fundamental to the types of operations that Polars’ query engine performs. Among other optimizations, it does: predicate pushdown (applying filters as early as possible), projection pushdown (selecting only the columns you need), simplification of expressions (replace expensive operations with faster alternatives, compilers do this type of thing), join ordering, common subplan elimination (cache subtress/file scans used by multiple subtrees in the query plan), slice pushdown (only load required slices of data from the scan), and schema checking (can you perform a given operation on a given column, happens before any data is touched). A query optimizer is such a powerful tool and is why Polars developers recommend you use LazyFrames as much as possible.[^lazyframes_note]

[^lazyframes_note]: You might be worried that you won’t be able to take as much advantage of this feature when you are exploring data and showing the data in intermediate stages. You are right, but you’ll still be getting better baseline performance than if you were using Pandas and even pushing down one filter before a join can have huge performance implications.

Polars’ API design contributes to its performance because it helps you write more expressive and robust code. Another quote from Stan Siebert is relevant here: “when you think about the time your program takes, think about the time you spent working on it as well as the time you spent running it.” You might be able to write really fast pandas code, but it may come at the expense of readability, modularity. When thinking about manipulating code in Polars, there are two key concepts: contexts and expressions. Contexts are methods on DataFrame that broadly describe what you’re doing, whether that’s selectings, filtering, grouping, or aggregating. Expressions are transformations that you call on Series.[^parallel_exp_note] The wonderful thing about Expressions is that they are very composable; much more so than operations in Pandas. If you’re using Expressions, you have all the speed of Polars available to you. This advantage shows up impressively when you want to apply more custom functions to groups of data in a grouped data set. In Pandas, if you want to get too custom, you have to use groupby().apply() with a lambda which kills performance. To get around this you may then have to write some more complicated and hard to read/maintain code. In Polars, if your custom function returns an Expression, you can use it in a groupby().agg() statement and not suffer a performance hit.

[^parallel_exp_note]: Polars parallelizes expressions across columns where appropriate.

Polars’ API is much less state-based, which also makes it easier to reason about the code you write. You don’t have to be thinking about whether or not you are operating on the original data, a view of the data, or a copy of the data. For example, there is no complicated indexing or multi-indexing in Polars and the reason they give is that it doesn’t help produce predictable results and readable queries. They say, “We believe the semantics of a query should not change by the state of an index or a reset_index call.” I for one, am happy to say goodbye to SettingWithCopyWarnings.

Returning to the Rust backend, the reason Polars piqued my interest is because I was also learning about Rust at the time. The language I have most experience in is Scala, a functional, compiled, statically-typed language. I liked the way the strictness of the language forced you to really think through a problem systematically and how the support a compiler gives you makes working on sprawling codebases much less stressful. I think that data scientists who adopt these more formalized approaches to programming, even just a little, end up performing better. However, the barrier to entry is high and managing ongoing training with delivering on your projects will always be a challenge. I think Polars can lower that barrier to entry by introducing concepts like lazy evaluation, type checking, working with nested data, folds, and algebraic data types. Even with this introduction however, there will be team members who have different interests in learning about these concepts and learning how to use a language like Rust for data science. For those who are though, Polars offers an opportunity for them to write more bespoke tools for their colleagues because it is relatively simple to integrate custom Rust code into Polars Python API. This is where the Polars/Python/Rust ecosystem excites me as a manager thinking about how to hire and develop my team, as well as someone who loves to create tools for data scientists.